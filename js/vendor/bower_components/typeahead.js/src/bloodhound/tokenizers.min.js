var tokenizers=(function(){return{nonword:a,whitespace:b,obj:{nonword:c(a),whitespace:c(b)}};function b(d){d=_.toStr(d);return d?d.split(/\s+/):[]}function a(d){d=_.toStr(d);return d?d.split(/\W+/):[]}function c(e){return function d(f){f=_.isArray(f)?f:[].slice.call(arguments,0);return function g(i){var h=[];_.each(f,function(j){h=h.concat(e(_.toStr(i[j])))});return h}}}})();